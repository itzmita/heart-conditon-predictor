{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c27697",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('FULL_RAW_ML_READY.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e31f4d",
   "metadata": {},
   "source": [
    "We will delete the following as those need not be used in Machine Learning and can be used in Visualizations\n",
    "Metropolitan_y_n, \n",
    "Urban_Rural, \n",
    "Reported_Income, \n",
    "Education_Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ba8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the columns State, index, Metropolitan_y_n, Urban_Rural, Reported_Income, Education_Level as its not needed for Machine Learning and can be utilized for visualizations\n",
    "df = df.drop([\"index\",\"State\",\"Metropolitan_y_n\",\"Urban_Rural\",\"Reported_Income\",\"Education_Level\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ad74a",
   "metadata": {},
   "source": [
    "From CDC website, we know for PHYSICAL_HEALTH we have \n",
    "when \"Physical_Health\"=1 then it means Zero days when physical health not good\n",
    "when \"Physical_Health\"=2 then it means 1-13 days when physical health not good\n",
    "when \"Physical_Health\"=3 then it means 14+ days when physical health not good\n",
    "when \"Physical_Health\"=9 then it means Donâ€™t know/ Refused/ Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17532ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Physical_Health\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b505e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Colonscopy NaNs into 3 bunches proportinately and update them with 1, 2, 3 to insert no bias to the model\n",
    "idx = df['Physical_Health'].index[df['Physical_Health']==9]\n",
    "df4 = df[df['Physical_Health'] != 9]\n",
    "x = df4['Physical_Health'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[1]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[2]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "sample3_perct = int((total_len*x[3]/100).round(1))\n",
    "print(sample3_perct)\n",
    "\n",
    "\n",
    "second_update = sample1_perct + sample2_perct\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Physical_Health'] = 1\n",
    "df.loc[idx[sample1_perct:second_update], 'Physical_Health'] = 2\n",
    "df.loc[idx[second_update:total_len], 'Physical_Health'] = 3\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f660069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Physical_Health\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5ffa3",
   "metadata": {},
   "source": [
    "from the CDC website document about this dataset, we came to know from the SAS code that\n",
    "Birth_Sex of 1 = Male and 2 = Female, we will change this to Male - 1 and Female - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique values for Sex\n",
    "df[\"Birth_Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Birth_Sex\"] == 2, \"Birth_Sex\"] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af5d61",
   "metadata": {},
   "source": [
    "As per the CDC website, the Age for this column was categorized as below\n",
    "when \"Age\"=1 then '18-24'\n",
    "when \"Age\"=2 then '25-29'\n",
    "when \"Age\"=3 then '30-34'\n",
    "when \"Age\"=4 then '35-39'\n",
    "when \"Age\"=5 then '40-44'\n",
    "when \"Age\"=6 then '45-49'\n",
    "when \"Age\"=7 then '50-54'\n",
    "when \"Age\"=8 then '55-59'\n",
    "when \"Age\"=9 then '60-64'\n",
    "when \"Age\"=10 then '65-69'\n",
    "when \"Age\"=11 then '70-74'\n",
    "when \"Age\"=12 then '75-79'\n",
    "when \"Age\"=13 then '80-84'\n",
    "when \"Age\"=14 then 'NaN' -- missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique values for Age - delete \n",
    "df[\"Age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936de53c",
   "metadata": {},
   "source": [
    "Looks like we have Age value 14 which were rows with missing values. Instead of dropping those rows, we will try to create 13 bunches of each value and add to the respective bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760dbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Age column with value 14 into 13 bunches and update them with 1, to 13 to insert no bias to the model\n",
    "idx = df['Age'].index[df['Age']==14]\n",
    "df4 = df[df['Age'] != 14]\n",
    "x = df4['Age'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[1]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[2]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "sample3_perct = int((total_len*x[3]/100).round(1))\n",
    "print(sample3_perct)\n",
    "sample4_perct = int((total_len*x[4]/100).round(1))\n",
    "print(sample4_perct)\n",
    "sample5_perct = int((total_len*x[5]/100).round(1))\n",
    "print(sample5_perct)\n",
    "sample6_perct = int((total_len*x[6]/100).round(1))\n",
    "print(sample6_perct)\n",
    "sample7_perct = int((total_len*x[7]/100).round(1))\n",
    "print(sample7_perct)\n",
    "sample8_perct = int((total_len*x[8]/100).round(1))\n",
    "print(sample8_perct)\n",
    "sample9_perct = int((total_len*x[9]/100).round(1))\n",
    "print(sample9_perct)\n",
    "sample10_perct = int((total_len*x[10]/100).round(1))\n",
    "print(sample10_perct)\n",
    "sample11_perct = int((total_len*x[11]/100).round(1))\n",
    "print(sample11_perct)\n",
    "sample12_perct = int((total_len*x[12]/100).round(1))\n",
    "print(sample12_perct)\n",
    "sample13_perct = int((total_len*x[13]/100).round(1))\n",
    "print(sample13_perct)\n",
    "\n",
    "\n",
    "second_update = sample1_perct + sample2_perct\n",
    "third_update = second_update + sample3_perct\n",
    "fourth_update = third_update + sample4_perct\n",
    "fifth_update = fourth_update + sample5_perct\n",
    "sixth_update = fifth_update + sample6_perct\n",
    "seventh_update = sixth_update + sample7_perct\n",
    "eight_update = seventh_update + sample8_perct\n",
    "ninth_update = eight_update + sample9_perct\n",
    "tenth_update = ninth_update + sample10_perct\n",
    "eleventh_update = tenth_update + sample11_perct\n",
    "twelveth_update = eleventh_update + sample12_perct\n",
    "thirteenth_update = twelveth_update + sample13_perct\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Age'] = 1\n",
    "df.loc[idx[sample1_perct:second_update], 'Age'] = 2\n",
    "df.loc[idx[second_update:third_update], 'Age'] = 3\n",
    "df.loc[idx[third_update:fourth_update], 'Age'] = 4\n",
    "df.loc[idx[fourth_update:fifth_update], 'Age'] = 5\n",
    "df.loc[idx[fifth_update:sixth_update], 'Age'] = 6\n",
    "df.loc[idx[sixth_update:seventh_update], 'Age'] = 7\n",
    "df.loc[idx[seventh_update:eight_update], 'Age'] = 8\n",
    "df.loc[idx[eight_update:ninth_update], 'Age'] = 9\n",
    "df.loc[idx[ninth_update:tenth_update], 'Age'] = 10\n",
    "df.loc[idx[tenth_update:eleventh_update], 'Age'] = 11\n",
    "df.loc[idx[eleventh_update:twelveth_update], 'Age'] = 12\n",
    "df.loc[idx[twelveth_update:total_len], 'Age'] = 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185caad4",
   "metadata": {},
   "source": [
    "--We know the following RACE from CDC website SAS code\n",
    "when \"Race\"=1 then 'White'\n",
    "when \"Race\"=2 then 'Black'\n",
    "when \"Race\"=3 then 'American Indian/Alaskan Native'\n",
    "when \"Race\"=4 then 'Asian'\n",
    "when \"Race\"=5 then 'Native Hawaiian or other Pacific Islander only, Non-Hispanic'\n",
    "when \"Race\"=6 then 'Other Race Only, Non-Hispanic'\n",
    "when \"Race\" = 7 then 'Multiracial, Non-Hispanic'\n",
    "when \"Race\"=8 then 'Hispanic'\n",
    "when \"Race\"=9 then missing values , equivalent to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bf5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unique values for Race delete\n",
    "df[\"Race\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ee86a",
   "metadata": {},
   "source": [
    "As we see the dataset contains the value 9 which is equivalent to NaN, we will try to modify these 8056 Races with derived values to each of the other valid Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Race column with value 9 into 8 bunches and update them with 1, to 8 to insert no bias to the model\n",
    "\n",
    "idx = df['Race'].index[df['Race']==9]\n",
    "df4 = df[df['Race'] != 9]\n",
    "x = df4['Race'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[1]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[2]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "sample3_perct = int((total_len*x[3]/100).round(1))\n",
    "print(sample3_perct)\n",
    "sample4_perct = int((total_len*x[4]/100).round(1))\n",
    "print(sample4_perct)\n",
    "sample5_perct = int((total_len*x[5]/100).round(1))\n",
    "print(sample5_perct)\n",
    "sample6_perct = int((total_len*x[6]/100).round(1))\n",
    "print(sample6_perct)\n",
    "sample7_perct = int((total_len*x[7]/100).round(1))\n",
    "print(sample7_perct)\n",
    "sample8_perct = int((total_len*x[8]/100).round(1))\n",
    "print(sample8_perct)\n",
    "\n",
    "\n",
    "\n",
    "second_update = sample1_perct + sample2_perct\n",
    "third_update = second_update + sample3_perct\n",
    "fourth_update = third_update + sample4_perct\n",
    "fifth_update = fourth_update + sample5_perct\n",
    "sixth_update = fifth_update + sample6_perct\n",
    "seventh_update = sixth_update + sample7_perct\n",
    "eight_update = seventh_update + sample8_perct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Race'] = 1\n",
    "df.loc[idx[sample1_perct:second_update], 'Race'] = 2\n",
    "df.loc[idx[second_update:third_update], 'Race'] = 3\n",
    "df.loc[idx[third_update:fourth_update], 'Race'] = 4\n",
    "df.loc[idx[fourth_update:fifth_update], 'Race'] = 5\n",
    "df.loc[idx[fifth_update:sixth_update], 'Race'] = 6\n",
    "df.loc[idx[sixth_update:seventh_update], 'Race'] = 7\n",
    "df.loc[idx[seventh_update:total_len], 'Race'] = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Race\n",
    "df[\"Race\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cd8aa",
   "metadata": {},
   "source": [
    "From the CDC website the SAS code for OVERALL_HEALTH says \n",
    "when \"Overall_Health\" = 1 then 'BETTER/GOOD'\n",
    "when \"Overall_Health\" = 2 then 'FAIR/POOR'\n",
    "when \"Overall_Health\"= 9 then Missing values\n",
    "So basically we can change 1 and 2 to 1 and 0 and instead of dropping the 9 rows, we can divide them equally into 1 and 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Overall Health - \n",
    "df[\"Overall_Health\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Overall_Health\"] == 2, \"Overall_Health\"] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Overall Health\n",
    "df[\"Overall_Health\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting rows with 9 as the number is less\n",
    "\n",
    "df = df[df.Overall_Health != 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14efb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Overall Health\n",
    "df[\"Overall_Health\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893ef83",
   "metadata": {},
   "source": [
    "BMI values can be in various number as each person's BMI will be different. \n",
    "Lets check if there are any missing ones. And if there are , let's have them filled in with the mean value of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BMI_CDC_Categories\"].isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c167c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean of values and update for rows which don't have a value\n",
    "mean_bmi = df['BMI_CDC_Categories'].mean()\n",
    "print('Mean of values in column BMI_CDC_Categories:')\n",
    "print(mean_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6418ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs in column BMI_CDC_Categories with the\n",
    "# mean of values in the same column\n",
    "df['BMI_CDC_Categories'].fillna(value=df['BMI_CDC_Categories'].mean(), inplace=True)\n",
    "print('Updated Dataframe:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a811a9b5",
   "metadata": {},
   "source": [
    "From the CDC website we know that for Diabetes\n",
    "when \"Diabetes\"=1 then 'Yes'\n",
    "when \"Diabetes\"=2 then 'Yes, but only Gestational Diabetes'\n",
    "when \"Diabetes\" =3 then 'No'\n",
    "when \"Diabetes\"=4 then 'Borderline Diabetes'\n",
    "when \"Diabetes\"=7 then 'NaN'\n",
    "when \"Diabetes\"=9 then 'refused to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Diabetes\n",
    "df[\"Diabetes\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437abad",
   "metadata": {},
   "source": [
    "So we see that there are 7 and 9 values which is equivalent to null/NaNs which we can spread them accross other values instead of deleting those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8adbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Diabetes column with value 7/9 into 4 bunches proportinately and update them with 1 to 4 to insert no bias to the model\n",
    "\n",
    "idx = df['Diabetes'].index[(df['Diabetes']==7) | (df['Diabetes']==9)]\n",
    "\n",
    "df4 = df[(df['Diabetes'] != 9) & (df['Diabetes'] != 7)]\n",
    "\n",
    "x = df4['Diabetes'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[1]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[2]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "sample3_perct = int((total_len*x[3]/100).round(1))\n",
    "print(sample3_perct)\n",
    "sample4_perct = int((total_len*x[4]/100).round(1))\n",
    "print(sample4_perct)\n",
    "\n",
    "second_update = sample1_perct + sample2_perct\n",
    "third_update = second_update + sample3_perct\n",
    "fourth_update = third_update + sample4_perct\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Diabetes'] = 1\n",
    "df.loc[idx[sample1_perct:second_update], 'Diabetes'] = 2\n",
    "df.loc[idx[second_update:third_update], 'Diabetes'] = 3\n",
    "df.loc[idx[third_update:total_len], 'Diabetes'] = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Diabetes\n",
    "df[\"Diabetes\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe11584",
   "metadata": {},
   "source": [
    "From CDC website, we know for Mental_Health we have \n",
    "when \"Mental_Health\"=1 then it means Zero days when physical health not good\n",
    "when \"Mental_Health\"=2 then it means 1-13 days when physical health not good\n",
    "when \"Mental_Health\"=3 then it means 14+ days when physical health not good\n",
    "when \"Mental_Health\"=9 then it means Donâ€™t know/ Refused/ Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f80b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Mental_Health  \n",
    "df[\"Mental_Health\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d70b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Mental_Health 9 into 3 bunches proportinately and update them with 1, 2, 3 to insert no bias to the model\n",
    "\n",
    "idx = df['Mental_Health'].index[df['Mental_Health']==9]\n",
    "df4 = df[df['Mental_Health'] != 9]\n",
    "x = df4['Mental_Health'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[1]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[2]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "sample3_perct = int((total_len*x[3]/100).round(1))\n",
    "print(sample3_perct)\n",
    "\n",
    "\n",
    "second_update = sample1_perct + sample2_perct\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Mental_Health'] = 1\n",
    "df.loc[idx[sample1_perct:second_update], 'Mental_Health'] = 2\n",
    "df.loc[idx[second_update:total_len], 'Mental_Health'] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699942a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Mental_Health\n",
    "df[\"Mental_Health\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974108fc",
   "metadata": {},
   "source": [
    "From the CDC website we know for Alcohol Usage\n",
    "when \"Alcohol_Usage\" = 1 then 'NO'\n",
    "when \"Alcohol_Usage\" = 2 then 'YES'\n",
    "when \"Alcohol_Usage\" = 9 then 'NaN'\n",
    "Lets get these values changed from 2 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132382e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Alcohol_Usage \n",
    "df[\"Alcohol_Usage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Alcohol_Usage\"] == 2, \"Alcohol_Usage\"] = 0\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Alcohol_Usage 9 into 2 bunches proportinately and update them with 1 or 0 to insert no bias to the model\n",
    "\n",
    "idx = df['Alcohol_Usage'].index[df['Alcohol_Usage']==9]\n",
    "df4 = df[df['Alcohol_Usage'] != 9]\n",
    "x = df4['Alcohol_Usage'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[0]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[1]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Alcohol_Usage'] = 0\n",
    "df.loc[idx[sample1_perct:total_len], 'Alcohol_Usage'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Alcohol_Usage\n",
    "df[\"Alcohol_Usage\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee860a",
   "metadata": {},
   "source": [
    "From the CDC website we know for Tobacco Usage\n",
    "when \"Tobacco_Usage\" = 1 then 'NO'\n",
    "when \"Tobacco_Usage\" = 2 then 'YES'\n",
    "when \"Tobacco_Usage\" = 9 then 'NaN'\n",
    "Lets get these values changed from 2 to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Tobacco_Usage \n",
    "df[\"Tobacco_Usage\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Tobacco_Usage\"] == 2, \"Tobacco_Usage\"] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780680bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Tobacco_Usage 9 into 2 bunches proportinately and update them with 1 or 0 to insert no bias to the model\n",
    "idx = df['Tobacco_Usage'].index[df['Tobacco_Usage']==9]\n",
    "df4 = df[df['Tobacco_Usage'] != 9]\n",
    "x = df4['Tobacco_Usage'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[0]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[1]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Tobacco_Usage'] = 0\n",
    "df.loc[idx[sample1_perct:total_len], 'Tobacco_Usage'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5eff5",
   "metadata": {},
   "source": [
    "From the CDC website we know for Asthma_History\n",
    "case when \"Asthma_History\"=1 then 'NO'\n",
    "when \"Asthma_History\"=2 then 'YES'\n",
    "when \"Asthma_History\"=9 then 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Asthma_History \n",
    "df[\"Asthma_History\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting Asthma_History 9  \n",
    "df = df[df.Asthma_History != 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Asthma_History\n",
    "df[\"Asthma_History\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d87e9d",
   "metadata": {},
   "source": [
    "We know that for Kidney_Disease\n",
    "when \"Kidney_Disease\"=1 then 'YES'\n",
    "when \"Kidney_Disease\"=2 then 'NO'\n",
    "when \"Kidney_Disease\"=7 then 'NaN'\n",
    "when \"Kidney_Disease\"=9 then Refused to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Kidney_Disease\n",
    "df[\"Kidney_Disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce853fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Kidney_Disease\"] == 2, \"Kidney_Disease\"] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dff6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Kidney_Disease column with value 7/9 into 2 bunches proportinately and update them with 1 or 0 to insert no bias to the model\n",
    "idx = df['Kidney_Disease'].index[(df['Kidney_Disease']==9) | (df['Kidney_Disease']==7)]\n",
    "df4 = df[(df['Kidney_Disease'] != 7) & (df['Kidney_Disease'] != 9)]\n",
    "x = df4['Kidney_Disease'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[0]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[1]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Kidney_Disease'] = 0\n",
    "df.loc[idx[sample1_perct:total_len], 'Kidney_Disease'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96783bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Kidney_Disease\n",
    "df[\"Kidney_Disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6232737",
   "metadata": {},
   "source": [
    "We know that for Stroke\n",
    "when \"Stroke\" = 1 then 'YES'\n",
    "when \"Stroke\" = 2 then 'NO'\n",
    "when \"Stroke\" = 7 then 'NaN'\n",
    "when \"Stroke\" = 9 then refused to answer\n",
    "end \"Stroke\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c16e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Stroke\n",
    "df[\"Stroke\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Stroke\"] == 2, \"Stroke\"] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Stroke column with value 7/9 into 2 bunches proportinately and update them with 1 or 0 to insert no bias to the model\n",
    "idx = df['Stroke'].index[(df['Stroke']==9) | (df['Stroke']==7)]\n",
    "df4 = df[(df['Stroke'] != 7) & (df['Stroke'] != 9)]\n",
    "x = df4['Stroke'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[0]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[1]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Stroke'] = 0\n",
    "df.loc[idx[sample1_perct:total_len], 'Stroke'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74288005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for Stroke\n",
    "df[\"Stroke\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9713a",
   "metadata": {},
   "source": [
    "We can see from above that Colonscopy column has some NaN values which we will modify to 1, 2, 3 in equal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4677ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Colonoscopy\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd0c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Colonscopy NaNs into 3 bunches proportinately and update them with 1, 2, 3 to insert no bias to the model\n",
    "\n",
    "# idx = df['Colonoscopy'].index[df['Colonoscopy']==9]\n",
    "idx=df['Colonoscopy'].index[df['Colonoscopy'].isna()]\n",
    "# df4 = df[df['Colonoscopy'] != 9]\n",
    "df4 = df[~df['Colonoscopy'].isna()]\n",
    "x = df4['Colonoscopy'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[1]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[2]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "sample3_perct = int((total_len*x[3]/100).round(1))\n",
    "print(sample3_perct)\n",
    "\n",
    "\n",
    "second_update = sample1_perct + sample2_perct\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Colonoscopy'] = 1\n",
    "df.loc[idx[sample1_perct:second_update], 'Colonoscopy'] = 2\n",
    "df.loc[idx[second_update:total_len], 'Colonoscopy'] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Colonoscopy\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f786ee7",
   "metadata": {},
   "source": [
    "CDC website says that for Prior Heart Disease\n",
    "when \"Prior_Heart_Disease\" = 1 then 'Yes, Reported Heart Disease'\n",
    "when \"Prior_Heart_Disease\" = 2 then 'No, Did Not Report Heart Disease'\n",
    "So we will change 2 to 0 for no heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc405c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prior_Heart_Disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Prior_Heart_Disease\"] == 2, \"Prior_Heart_Disease\"] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ffe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prior_Heart_Disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d933a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Prior_Heart_Disease\": \"Heart_Disease\"}, errors=\"raise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a58081",
   "metadata": {},
   "source": [
    "We know from CDC website that for Physical Activity\n",
    "when \"Physical_Activity\" = 1 then 'Yes, Physical Activities'\n",
    "when \"Physical_Activity\" = 2 then 'No Physical Activities'\n",
    "else 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Physical_Activity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Physical_Activity\"] == 2, \"Physical_Activity\"] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Physical_Activity column with value 9 into 2 bunches proportinately and update them with 1 or 0 to insert no bias to the model\n",
    "\n",
    "idx = df['Physical_Activity'].index[df['Physical_Activity']==9]\n",
    "df4 = df[df['Physical_Activity'] != 9]\n",
    "x = df4['Physical_Activity'].value_counts(normalize=True) * 100\n",
    "total_len = len(idx)\n",
    "print(total_len)\n",
    "sample1_perct = int((total_len*x[0]/100).round(1))\n",
    "print(sample1_perct) \n",
    "sample2_perct = int((total_len*x[1]/100).round(1)) \n",
    "print(sample2_perct)\n",
    "\n",
    "\n",
    "df.loc[idx[0:sample1_perct], 'Physical_Activity'] = 0\n",
    "df.loc[idx[sample1_perct:total_len], 'Physical_Activity'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Physical_Activity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Avg_Hours_of_Sleep\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc5614",
   "metadata": {},
   "source": [
    "If we see from above there are rows where the number of hours of sleep is more than 24 hours. Lets have them deleted if its less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47613ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Avg_Hours_of_Sleep'] > 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646447ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows where number of hours is more than 24 \n",
    "df = df[df.Avg_Hours_of_Sleep <= 24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061ab30b",
   "metadata": {},
   "source": [
    "Lets check if all data are clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5608c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f3cc8",
   "metadata": {},
   "source": [
    "From the above we see that there are some NaN rows, we can delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7447c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13cfe1",
   "metadata": {},
   "source": [
    "Now the dataset looks clean and is ready for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns with 2 categories which already has 0 and 1 values. so no neeed to do Label encoding\n",
    "cat_col = ['Birth_Sex', 'Overall_Health', 'Alcohol_Usage', 'Tobacco_Usage', 'Asthma_History', 'Kidney_Disease', 'Stroke', 'Physical_Activity']\n",
    "# categorical columns with more than 2 unqiue values\n",
    "encode_col = ['Age', 'Race', 'Physical_Health', 'BMI_CDC_Categories', 'Diabetes', 'Mental_Health', 'Colonoscopy']\n",
    "\n",
    "df[encode_col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5db75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df[encode_col]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(encode_col)\n",
    "encode_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "df = df.merge(encode_df,left_index=True, right_index=True)\n",
    "df = df.drop(encode_col,1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df696cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2[\"Heart_Disease\"]\n",
    "X = df2.drop(columns=\"Heart_Disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ab660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x = \"Heart_Disease\", data = df)\n",
    "df.loc[:, 'Heart_Disease'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b223e",
   "metadata": {},
   "source": [
    "From the above we can see that the dataset is not balanced, there are way more number of samples for people who have no Heart Disease than people with Heart Disease.\n",
    "This can be fixed by oversampling the data. We will use RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement random oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "# X_scaler = scaler.fit(X_train)\n",
    "X_scaler = scaler.fit(X_resampled)\n",
    "\n",
    "# Scaling the data.\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_resampled)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec613cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e732fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating various classifier instances as a list.\n",
    "\n",
    "models = [LogisticRegression(solver='liblinear', random_state=1), \n",
    "          DecisionTreeClassifier(), \n",
    "          ExtraTreesClassifier(random_state=1, n_estimators=100), \n",
    "          RandomForestClassifier(n_estimators=100, random_state=1)          \n",
    "          ]\n",
    "\n",
    "compare = pd.DataFrame(columns=[\"Model\", \"F1\", \"Recall\", \"Accuracy\", \"Probability\", \"Prediction\"])\n",
    "acc_list = []\n",
    "\n",
    "for m in models:\n",
    "    m.fit(X_resampled, y_resampled)\n",
    "    y_pred = m.predict(X_test_scaled)\n",
    "    y_prob = m.predict_proba(X_test_scaled)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    \n",
    "    compare = compare.append({'Model': m, 'F1': f1, 'Recall': recall, 'Accuracy': acc, 'Probability': y_prob, 'Prediction': y_pred}, ignore_index=True)\n",
    "    acc_list.append(acc)\n",
    "    print(f'Model used: {m}')\n",
    "    print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')\n",
    "    print(f'Precision Score: {precision_score(y_test,y_pred)}')\n",
    "    print(f'Recall Score: {recall_score(y_test,y_pred)}')\n",
    "    print(f'F1 Score: {f1_score(y_test,y_pred)}')\n",
    "    print(f'Probability: {y_prob}')\n",
    "    print(f'Prediction: {y_pred}')\n",
    "    print('-------------------------------------', '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f310f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b129482",
   "metadata": {},
   "source": [
    "Lets try Logistic regression with taking away different columns and see the impact in accuracy, recall etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cdd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regress_iteration(df, drop_col, compare_log):\n",
    "    df2 = df.copy()\n",
    "    y = df2[\"Heart_Disease\"]\n",
    "    \n",
    "    X = df2.loc[:,~df2.columns.str.contains(drop_col)].drop(columns='Heart_Disease')\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Creating a StandardScaler instance.\n",
    "    scaler = StandardScaler()\n",
    "    # Fitting the Standard Scaler with the training data.\n",
    "    X_scaler = scaler.fit(X_resampled)\n",
    "\n",
    "    # Scaling the data.\n",
    "    X_train_scaled = X_scaler.transform(X_resampled)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    # Creating various classifier instances as a list.\n",
    "\n",
    "    log_model = LogisticRegression(solver='liblinear', random_state=1)   \n",
    "\n",
    "\n",
    "    log_model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    y_pred = log_model.predict(X_test_scaled)\n",
    "    y_prob = log_model.predict_proba(X_test_scaled)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred, pos_label='positive', average=None)\n",
    "\n",
    "    compare_log = compare_log.append({'Model': log_model, 'drop column': drop_col, 'F1': f1, 'Recall': recall, 'Accuracy': acc, 'Probability': y_prob, 'Prediction': y_pred}, ignore_index=True)\n",
    "    return compare_log\n",
    "    print(f'Model used: {str(log_model)}')\n",
    "    print(f'Drop Column: {drop_col}')\n",
    "    print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')\n",
    "    print(f'Precision Score: {precision_score(y_test,y_pred)}')\n",
    "    print(f'Recall Score: {recall_score(y_test,y_pred)}')\n",
    "    print(f'F1 Score: {f1_score(y_test,y_pred)}')\n",
    "    print(f'Probability: {y_prob}')\n",
    "    print(f'Prediction: {y_pred}')\n",
    "    print('-------------------------------------', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compare_log = pd.DataFrame(columns=[\"Model\", \"drop column\", \"F1\", \"Recall\", \"Accuracy\", \"Probability\", \"Prediction\"])\n",
    "birth_sex = log_regress_iteration(df, \"Birth_Sex\", compare_log)\n",
    "age = log_regress_iteration(df, \"Age\", birth_sex)\n",
    "race = log_regress_iteration(df, \"Race\", age)\n",
    "overall_health = log_regress_iteration(df, \"Overall_Health\", race)\n",
    "physical_health = log_regress_iteration(df, \"Physical_Health\", overall_health)\n",
    "bmi = log_regress_iteration(df, \"BMI_CDC_Categories\", physical_health)\n",
    "diabetes = log_regress_iteration(df, \"Diabetes\", bmi)\n",
    "mental_Health = log_regress_iteration(df, \"Mental_Health\", diabetes)\n",
    "alcohol_Usage = log_regress_iteration(df, \"Alcohol_Usage\", mental_Health)\n",
    "tobacco_Usage = log_regress_iteration(df, \"Tobacco_Usage\", alcohol_Usage)\n",
    "asthma_History = log_regress_iteration(df, \"Asthma_History\", tobacco_Usage)\n",
    "kidney_Disease = log_regress_iteration(df, \"Kidney_Disease\", asthma_History)\n",
    "stroke = log_regress_iteration(df, \"Stroke\", kidney_Disease)\n",
    "colonoscopy = log_regress_iteration(df, \"Colonoscopy\", stroke)\n",
    "physical_Activity = log_regress_iteration(df, \"Physical_Activity\", colonoscopy)\n",
    "sleep_time = log_regress_iteration(df, \"Avg_Hours_of_Sleep\", physical_Activity)\n",
    "\n",
    "final_df = sleep_time.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e448f9",
   "metadata": {},
   "source": [
    "here we try dropping the Kidney_disease and Age to see the impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7be7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "y = df2[\"Heart_Disease\"]\n",
    "\n",
    "X = df2.loc[:,~df2.columns.str.contains(\"Age\")].drop(columns='Heart_Disease').drop(columns='Kidney_Disease')\n",
    "drop_col = \"KidneyandAge\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_resampled)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_resampled)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "# Creating various classifier instances as a list.\n",
    "\n",
    "log_model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "\n",
    "\n",
    "\n",
    "log_model.fit(X_resampled, y_resampled)\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "y_prob = log_model.predict_proba(X_test_scaled)\n",
    "f1 = f1_score(y_test,y_pred)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "recall = recall_score(y_test,y_pred, pos_label='positive', average=None)\n",
    "\n",
    "compare_log = compare_log.append({'Model': log_model, 'drop column': drop_col, 'F1': f1, 'Recall': recall, 'Accuracy': acc, 'Probability': y_prob, 'Prediction': y_pred}, ignore_index=True)\n",
    "print(f'Model used: {str(log_model)}')\n",
    "print(f'Drop Column: {drop_col}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_pred)}')\n",
    "print(f'Precission Score: {precision_score(y_test,y_pred)}')\n",
    "print(f'Recall Score: {recall_score(y_test,y_pred)}')\n",
    "print(f'F1 Score: {f1_score(y_test,y_pred)}')\n",
    "print(f'Probability: {y_prob}')\n",
    "print(f'Prediction: {y_pred}')\n",
    "print('-------------------------------------', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f67fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lables = [ \"Logistic Regression\", \"DecisionTree\",\"ExtraTree\", \"RandomForest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = acc_lables\n",
    "y_axis = acc_list\n",
    "colors = ['pink', 'yellow', 'orange', 'magenta']\n",
    "\n",
    "# Create the plot\n",
    "# setting figure size by using figure() function \n",
    "plt.figure(figsize = (15, 7))\n",
    "      \n",
    "bars = plt.bar(x_axis, y_axis, color=colors, label='Accuracy')\n",
    "plt.xlabel(\"Classifier Models\", fontsize = 20 )\n",
    "plt.ylabel(\"% of Accuracy\", fontsize = 20)\n",
    "plt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\n",
    "plt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 50)\n",
    "plt.yticks(fontsize = 13)\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x(), yval/2, yval*100)\n",
    "    \n",
    "# Add the legend.\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f33fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
